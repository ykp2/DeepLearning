{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "MNIST data set is a collection of 70,000 handwriting image samples of the numbers 0-9. Our goal is to predict the number each handwritten image represents. Each image is 28x28 grayscale pixels, so we can treat each image as just a 1D array, or tensor, of 784 numbers. MNIST provides 60,000 samples in the training set, and 10,000 samples in the test set. The goal is to use Deep Learning to train a Neural Network to \"read\" the number represented in a image.\n",
    "\n",
    "We'll start by importing the data set, like we did for the Tensorflow implementation. Keras is a higher-level API within TensorFlow that makes things a lot easier. Not only is it easier to use, it's easier to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = mnist_train_images.reshape(60000, 784)\n",
    "test_images = mnist_test_images.reshape(10000, 784)\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "# Normalize images value from [0, 255] to [0, 1]\n",
    "train_images /= 255\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert the 0-9 labels into \"one-hot\" format. Think of one_hot as a binary representation of the label data - that is, which number each handwriting sample was intended to represent. Mathematically one_hot represents a dimension for every possible label value. Every dimension is set to the value 0, except for the \"correct\" one which is set to 1. For example, the label vector representing the number 1 would be [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] (remember we start counting at 0.) It's just a format that's optimized for how the labels are applied during training.\n",
    "\n",
    "So the training label data is a tensor of shape [60,000, 10] - 60,000 test images each associated with 10 binary values that indicate whether or not the image represents a given number from 0-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = keras.utils.to_categorical(mnist_train_labels, 10)\n",
    "test_labels = keras.utils.to_categorical(mnist_test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a sample image from training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_sample(num):\n",
    "    #Print the one-hot array of this sample's label \n",
    "    print(train_labels[num])  \n",
    "    #Print the label converted back to a number\n",
    "    label = train_labels[num].argmax(axis=0)\n",
    "    #Reshape the 768 values to a 28x28 image\n",
    "    image = train_images[num].reshape([28,28])\n",
    "    plt.title('Sample: %d  Label: %d' % (num, label))\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.show()\n",
    "    \n",
    "display_sample(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set up layers the same way we did for Tensorflow implementation. The input layer of 784 features feeds into a ReLU (Note: we used sigmoid activation for Tensofrflow) layer of 256 nodes, which feeds into ReLU layer of 256 nodes, which then goes into 10 nodes with softmax applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\patil\\Anaconda3\\envs\\RecSys\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(100, activation='relu', input_shape=(256,)))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras let's you get a summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 227,670\n",
      "Trainable params: 227,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will set up the optimizer and loss function. We will use the RMSProp optimizer here. Some other choices are Adagrad, SGD, Adam, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train the model over 10 epochs with a batch size of 100. Keras is slower than Tensorflow (since it performs more computation) so we use fewer epochs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 - 2s - loss: 0.2471 - acc: 0.9268 - val_loss: 0.1267 - val_acc: 0.9592\n",
      "Epoch 2/10\n",
      "60000/60000 - 2s - loss: 0.0966 - acc: 0.9703 - val_loss: 0.0918 - val_acc: 0.9699\n",
      "Epoch 3/10\n",
      "60000/60000 - 2s - loss: 0.0657 - acc: 0.9803 - val_loss: 0.0735 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      "60000/60000 - 2s - loss: 0.0476 - acc: 0.9856 - val_loss: 0.0809 - val_acc: 0.9772\n",
      "Epoch 5/10\n",
      "60000/60000 - 2s - loss: 0.0374 - acc: 0.9886 - val_loss: 0.0754 - val_acc: 0.9786\n",
      "Epoch 6/10\n",
      "60000/60000 - 2s - loss: 0.0283 - acc: 0.9906 - val_loss: 0.0887 - val_acc: 0.9777\n",
      "Epoch 7/10\n",
      "60000/60000 - 2s - loss: 0.0234 - acc: 0.9929 - val_loss: 0.0704 - val_acc: 0.9815\n",
      "Epoch 8/10\n",
      "60000/60000 - 2s - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0868 - val_acc: 0.9787\n",
      "Epoch 9/10\n",
      "60000/60000 - 2s - loss: 0.0152 - acc: 0.9953 - val_loss: 0.0746 - val_acc: 0.9812\n",
      "Epoch 10/10\n",
      "60000/60000 - 2s - loss: 0.0124 - acc: 0.9960 - val_loss: 0.0830 - val_acc: 0.9814\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=100,\n",
    "                    epochs=10,\n",
    "                    verbose=2,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With just 10 epochs, we have a much better accuracy than the Tensorflow version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08297156737679534\n",
      "Test accuracy: 0.9814\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll visualize that were incorrectly labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in range(300):\n",
    "    test_image = test_images[x,:].reshape(1,784)\n",
    "    predicted_cat = model.predict(test_image).argmax()\n",
    "    label = test_labels[x].argmax()\n",
    "    if (predicted_cat != label):\n",
    "        plt.title('Prediction: %d Label: %d' % (predicted_cat, label))\n",
    "        plt.imshow(test_image.reshape([28,28]), cmap=plt.get_cmap('gray_r'))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks:\n",
    "\n",
    "We could further improve the performance of the model by selecting the optimal hyperparameters such as number of hidden layers in the neural network, number of units within the hidden layers, learning rate, epochs or even a different optimizer.\n",
    "\n",
    "We can see that for the same architecture of the neural network, Keras implementation has a better accuracy. This is likely due to the fact that we used a different optimizer (RMSProp v/s SGD) as well as different activation function (ReLU v/s Sigmoid) in Keras as compared to Tensorflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
